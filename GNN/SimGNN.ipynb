{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of SimGAE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Firslty install several relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rDLaYKY_rQCI",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://repo.huaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: scipy in ./miniconda3/lib/python3.8/site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in ./miniconda3/lib/python3.8/site-packages (from scipy) (1.24.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://repo.huaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: torch_geometric in ./miniconda3/lib/python3.8/site-packages (2.3.0)\n",
      "Requirement already satisfied: jinja2 in ./miniconda3/lib/python3.8/site-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: numpy in ./miniconda3/lib/python3.8/site-packages (from torch_geometric) (1.24.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in ./miniconda3/lib/python3.8/site-packages (from torch_geometric) (5.9.4)\n",
      "Requirement already satisfied: requests in ./miniconda3/lib/python3.8/site-packages (from torch_geometric) (2.28.2)\n",
      "Requirement already satisfied: scipy in ./miniconda3/lib/python3.8/site-packages (from torch_geometric) (1.10.1)\n",
      "Requirement already satisfied: tqdm in ./miniconda3/lib/python3.8/site-packages (from torch_geometric) (4.61.2)\n",
      "Requirement already satisfied: pyparsing in ./miniconda3/lib/python3.8/site-packages (from torch_geometric) (3.0.9)\n",
      "Requirement already satisfied: scikit-learn in ./miniconda3/lib/python3.8/site-packages (from torch_geometric) (1.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./miniconda3/lib/python3.8/site-packages (from jinja2->torch_geometric) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniconda3/lib/python3.8/site-packages (from requests->torch_geometric) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.8/site-packages (from requests->torch_geometric) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./miniconda3/lib/python3.8/site-packages (from requests->torch_geometric) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/lib/python3.8/site-packages (from requests->torch_geometric) (2.10)\n",
      "Requirement already satisfied: joblib>=1.0.0 in ./miniconda3/lib/python3.8/site-packages (from scikit-learn->torch_geometric) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./miniconda3/lib/python3.8/site-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "torchversion = torch.version.__version__\n",
    "!pip install scipy\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{torchversion}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{torchversion}.html\n",
    "!pip install torch_geometric\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.spatial import Delaunay\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as T\n",
    "import sys\n",
    "import scipy.sparse as sp\n",
    "import math\n",
    "from numpy.linalg import inv, pinv\n",
    "from torch.nn import Softmax\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score,average_precision_score\n",
    "from torch.nn.init import xavier_normal_ as xavier\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Then, define some functions for computing hodge laplacians for 2-simplex.\n",
    "\n",
    "The version of higher simplexes is in working. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DvgRU1ppiHuG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_faces(G):\n",
    "    \"\"\"\n",
    "    Returns a list of the faces of 2-simplexes in an undirected graph\n",
    "    i.e, triangle is a 2-simplex in an undirected graph and each edge of this triangle is a face of this triangle\n",
    "    \"\"\"\n",
    "    edges = list(G.edges)\n",
    "    faces = []\n",
    "    for i in range(len(edges)):\n",
    "        for j in range(i+1, len(edges)):\n",
    "            e1 = edges[i]\n",
    "            e2 = edges[j]\n",
    "            if e1[0] == e2[0]:\n",
    "                shared = e1[0]\n",
    "                e3 = (e1[1], e2[1])\n",
    "            elif e1[1] == e2[0]:\n",
    "                shared = e1[1]\n",
    "                e3 = (e1[0], e2[1])\n",
    "            elif e1[0] == e2[1]:\n",
    "                shared = e1[0]\n",
    "                e3 = (e1[1], e2[0])\n",
    "            elif e1[1] == e2[1]:\n",
    "                shared = e1[1]\n",
    "                e3 = (e1[0], e2[0])\n",
    "            else:  # edges don't connect\n",
    "                continue\n",
    "\n",
    "            if e3[0] in G[e3[1]]: # if 3rd edge is in graph\n",
    "                faces.append(tuple(sorted((shared, *e3))))\n",
    "    return list(sorted(set(faces)))\n",
    "\n",
    "\n",
    "def incidence_matrices(G, V, E, faces, edge_to_idx):\n",
    "    \"\"\"\n",
    "    Returns incidence matrices B1 and B2\n",
    "    :param G: NetworkX DiGraph\n",
    "    :param V: list of nodes\n",
    "    :param E: list of edges\n",
    "    :param faces: list of faces in G\n",
    "    Returns B1 (|V| x |E|) and B2 (|E| x |faces|)\n",
    "    B1[i][j]: -1 if node is is tail of edge j, 1 if node is head of edge j, else 0 (tail -> head) (smaller -> larger)\n",
    "    B2[i][j]: 1 if edge i appears sorted in face j, -1 if edge i appears reversed in face j, else 0; given faces with sorted node order\n",
    "    \"\"\"\n",
    "    B1 = np.array(nx.incidence_matrix(G, nodelist=V, edgelist=E, oriented=True).todense())\n",
    "    B2 = np.zeros([len(E),len(faces)])\n",
    "\n",
    "    for f_idx, face in enumerate(faces): # face is sorted\n",
    "        edges = [face[:-1], face[1:], [face[0], face[2]]]\n",
    "        e_idxs = [edge_to_idx[tuple(e)] for e in edges]\n",
    "\n",
    "        B2[e_idxs[:-1], f_idx] = 1\n",
    "        B2[e_idxs[-1], f_idx] = -1\n",
    "    return B1, B2\n",
    "\n",
    "\n",
    "def compute_D2(B):\n",
    "    \"\"\"\n",
    "    Computes D2 = max(diag(dot(|B|, 1)), I)\n",
    "    \"\"\"\n",
    "    B_rowsum = np.abs(B).sum(axis=1)\n",
    "\n",
    "    D2 = np.diag(np.maximum(B_rowsum, 1))\n",
    "    return D2\n",
    "\n",
    "def compute_D1(B1, D2):\n",
    "    \"\"\"\n",
    "    Computes D1 = 2 * max(diag(|B1|) .* D2\n",
    "    \"\"\"\n",
    "    rowsum = (np.abs(B1) @ D2).sum(axis=1)\n",
    "    D1 = 2 * np.diag(rowsum)\n",
    "\n",
    "    return D1\n",
    "\n",
    "\n",
    "\n",
    "def compute_hodge_matrices(B1, B2):\n",
    "    \"\"\"\n",
    "    Computes normalized Hodge Laplacians L0 and L1 matrices,\n",
    "    \"\"\"\n",
    "    # D matrices\n",
    "    D2_2 = compute_D2(B2)\n",
    "    D2_1 = compute_D2(B1)\n",
    "    D3_n = np.identity(B1.shape[1]) # (|E| x |E|)\n",
    "    D1 = compute_D1(B1, D2_2)\n",
    "    D3 = np.identity(B2.shape[1]) / 3 # (|F| x |F|)\n",
    "\n",
    "    # L matrices\n",
    "    D1_pinv = pinv(D1)\n",
    "    D2_2_inv = inv(D2_2)\n",
    "\n",
    "\n",
    "    L0u = B1 @ D3_n @ B1.T @ inv(D2_1) #B1.T @ B1 \n",
    "    L1u = D2_2 @ B1.T @ D1_pinv @ B1\n",
    "    L1d = B2 @ D3 @ B2.T @ D2_2_inv\n",
    "    L1f = L1u + L1d\n",
    "    \n",
    "    # print(B1.shape)\n",
    "    # print(B2.shape)\n",
    "    # print(L0u.shape)\n",
    "    # print(L1u.shape)    \n",
    "    # print(L1d.shape)\n",
    "    # # print(L1f.shape)\n",
    "    return L0u, L1f\n",
    "\n",
    "def compute_boundary_matrix(data, sample_data_edge_index):\n",
    "    \"compute boundary matrix of Node\"\n",
    "    g = nx.Graph()\n",
    "    g.add_nodes_from([i for i in range(len(data.y))])\n",
    "    edge_index_ = np.array((sample_data_edge_index))\n",
    "    edge_index = [(edge_index_[0, i], edge_index_[1, i]) for i in\n",
    "                        range(np.shape(edge_index_)[1])]\n",
    "    g.add_edges_from(edge_index)\n",
    "\n",
    "    edge_to_idx = {edge: i for i, edge in enumerate(g.edges)}\n",
    "\n",
    "    B1, B2 = incidence_matrices(g, sorted(g.nodes), sorted(g.edges), get_faces(g), edge_to_idx)\n",
    "    print(B1.shape)\n",
    "    print(B2.shape)\n",
    "\n",
    "    return B1, B2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Compared to other typical GNN network, it takes hodge_laplacians of 1-simplex and 2=simplex as input. The version of higher simplexes is in working. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SIMGAE(torch.nn.Module):\n",
    "    def __init__(self,data,num_features,num_classes,hodge_laplacians,dimension=8):\n",
    "        super(SIMGAE, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 64, cached=True)\n",
    "        self.conv2 = GCNConv(64, 32, cached=True)\n",
    "        self.hodge_laplacians = hodge_laplacians\n",
    "        self.leakyrelu = torch.nn.LeakyReLU(0.2, True)\n",
    "        self.linear = torch.nn.Linear(32, 1, bias=True)\n",
    "        self.linear_1 = torch.nn.Linear(dimension + 32, 32, bias=True)\n",
    "        self.softmax = Softmax(dim=1)\n",
    "        hodge_laplacian0_size = self.hodge_laplacians[0].size(0)\n",
    "        hodge_laplacian1_size = self.hodge_laplacians[1].size(0)\n",
    "        self.weights_sim = nn.Parameter(torch.FloatTensor(int(hodge_laplacian0_size+hodge_laplacian1_size), dimension))\n",
    "        self.embeddings_sim = nn.Parameter(torch.FloatTensor(data.x.size(1), int(hodge_laplacian0_size+hodge_laplacian1_size)))\n",
    "\n",
    "        # reset parameters\n",
    "        nn.init.kaiming_uniform_(self.weights_sim, mode = 'fan_out', a = math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.embeddings_sim, mode='fan_out', a=math.sqrt(5))\n",
    "\n",
    "    def g_encode(self,data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x,p=0.5,training=self.training)\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        return x\n",
    "\n",
    "    def s_encode(self,data,g_emb,type=\"train\"):\n",
    "        if type == 'train':\n",
    "            edges_pos = data.total_edges[:data.train_pos]\n",
    "            index = np.random.randint(0, data.train_neg, data.train_pos)\n",
    "            edges_neg = data.total_edges[data.train_pos:data.train_pos + data.train_neg][index]\n",
    "            total_edges = np.concatenate((edges_pos,edges_neg))\n",
    "            edges_y = torch.cat((data.total_edges_y[:data.train_pos],data.total_edges_y[data.train_pos:data.train_pos + data.train_neg][index]))\n",
    "\n",
    "        elif type == 'val':\n",
    "            total_edges =  data.total_edges[data.train_pos+data.train_neg:data.train_pos+data.train_neg+data.val_pos+data.val_neg]\n",
    "            edges_y = data.total_edges_y[data.train_pos+data.train_neg:data.train_pos+data.train_neg+data.val_pos+data.val_neg]\n",
    "\n",
    "        elif type == 'test':\n",
    "            total_edges = data.total_edges[\n",
    "                          data.train_pos + data.train_neg + data.val_pos + data.val_neg:]\n",
    "            edges_y = data.total_edges_y[\n",
    "                      data.train_pos + data.train_neg + data.val_pos + data.val_neg :]\n",
    "\n",
    "\n",
    "        L0, L1 = self.hodge_laplacians\n",
    "        L0_r = torch.matrix_power(L0, 1)\n",
    "        L1_r = torch.matrix_power(L1, 1)\n",
    "        #print(L0.size())\n",
    "        #print(L1.size())\n",
    "        diag_zeros = torch.zeros(L0.size()[0], L1.size()[1]).to(L0.device)\n",
    "        upper_block = torch.cat([L0_r, diag_zeros], dim=1)\n",
    "        lower_block = torch.cat([diag_zeros.T, L1_r], dim=1)\n",
    "        sim_block = torch.cat([upper_block, lower_block], dim=0)\n",
    "\n",
    "        x = data.x\n",
    "        embeddings_sim = torch.matmul(x, self.embeddings_sim)\n",
    "        s_emb_sim_ = torch.matmul(embeddings_sim, sim_block)  \n",
    "        s_emb_sim = torch.matmul(s_emb_sim_, self.weights_sim)\n",
    "        s_emb_sim = s_emb_sim.renorm_(2, 0, 1)\n",
    "\n",
    "        s_emb_sim_in = s_emb_sim[total_edges[:, 0]]\n",
    "        s_emb_sim_out = s_emb_sim[total_edges[:, 1]]\n",
    "\n",
    "        d_sim = (s_emb_sim_in - s_emb_sim_out).pow(2)\n",
    "\n",
    "        # linear to gather edge features\n",
    "        # embedding from GCN\n",
    "        g_emb = g_emb.renorm_(2,0,1)\n",
    "        alpha = 1.0\n",
    "        beta = 0.1\n",
    "\n",
    "        g_emb_in = g_emb[total_edges[:, 0]]\n",
    "        g_emb_out = g_emb[total_edges[:, 1]]\n",
    "        g_sqdist = (g_emb_in - g_emb_out).pow(2)\n",
    "        sqdist = self.leakyrelu(self.linear_1(torch.cat((alpha * g_sqdist, beta * d_sim), dim=1)))\n",
    "        sqdist = torch.abs(self.linear(sqdist)).reshape(-1)\n",
    "        sqdist = torch.clamp(sqdist, min=0, max=40)\n",
    "        prob = 1. / (torch.exp((sqdist - 2.0) / 1.0) + 1.0)\n",
    "        return prob, edges_y.float()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Following the pytorch official tutorial of Link Prediction using Graph Neural Networks. Then, define some functions.\n",
    "\n",
    "Formulate the link prediction problem as a binary classification. \n",
    "\n",
    "These functions are for \n",
    "\n",
    "1. Treat the edges in the graph as positive examples.\n",
    "2. Sample a number of non-existent edges (i.e. node pairs with no edges between them) as negative examples.\n",
    "Divide the positive examples and negative examples into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MfjN0GmajZ9o",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_edges_split(data, val_prop = 0.2, test_prop = 0.2):\n",
    "    g = nx.Graph()\n",
    "    g.add_nodes_from([i for i in range(len(data.y))])\n",
    "    _edge_index_ = np.array((data.edge_index))\n",
    "    edge_index_ = [(_edge_index_[0, i], _edge_index_[1, i]) for i in\n",
    "                        range(np.shape(_edge_index_)[1])]\n",
    "    g.add_edges_from(edge_index_)\n",
    "    adj = nx.adjacency_matrix(g)\n",
    "\n",
    "    return get_adj_split(adj,val_prop = val_prop, test_prop = test_prop)\n",
    "\n",
    "def get_adj_split(adj, val_prop=0.05, test_prop=0.1):\n",
    "    x, y = sp.triu(adj).nonzero()\n",
    "    pos_edges = np.array(list(zip(x, y)))\n",
    "    np.random.shuffle(pos_edges)\n",
    "    # get tn edges\n",
    "    x, y = sp.triu(sp.csr_matrix(1. - adj.toarray())).nonzero()\n",
    "    neg_edges = np.array(list(zip(x, y)))\n",
    "    np.random.shuffle(neg_edges)\n",
    "\n",
    "    m_pos = len(pos_edges)\n",
    "    n_val = int(m_pos * val_prop)\n",
    "    n_test = int(m_pos * test_prop)\n",
    "    val_edges, test_edges, train_edges = pos_edges[:n_val], pos_edges[n_val:n_test + n_val], pos_edges[n_test + n_val:]\n",
    "    val_edges_false, test_edges_false = neg_edges[:n_val], neg_edges[n_val:n_test + n_val]\n",
    "    train_edges_false = np.concatenate([neg_edges, val_edges, test_edges], axis=0)\n",
    "    return train_edges, train_edges_false, val_edges, val_edges_false, test_edges, test_edges_false\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train, test, weights_init, setup_seed are some network training preliminary function.\n",
    "### Call function interaget the loading data, creating model and setiing parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nOVrw-4qkw28",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    emb = model.g_encode(data).clone()\n",
    "    x, y = model.s_encode(data, emb)  # emb from encode's, i.e., Gconv's output\n",
    "    loss = F.binary_cross_entropy(x,y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #scheduler.step()\n",
    "    return x\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    accs = []\n",
    "    emb = model.g_encode(data)\n",
    "    for type in [\"val\", \"test\"]:\n",
    "        pred,y = model.s_encode(data,emb,type=type)\n",
    "        pred,y = pred.cpu(),y.cpu()\n",
    "        if type == \"val\":\n",
    "            accs.append(F.binary_cross_entropy(pred, y))\n",
    "            pred = pred.data.numpy()\n",
    "            roc = roc_auc_score(y, pred)\n",
    "            accs.append(roc)\n",
    "            acc = average_precision_score(y,pred)\n",
    "            accs.append(acc)\n",
    "        else:\n",
    "            pred = pred.data.numpy()\n",
    "            roc = roc_auc_score(y, pred)\n",
    "            accs.append(roc)\n",
    "            acc = average_precision_score(y, pred)\n",
    "            accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        xavier(m.weight)\n",
    "        if not m.bias is None:\n",
    "            torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def call(data,name,num_features,num_classes):\n",
    "    val_prop = 0.05\n",
    "    test_prop = 0.1\n",
    "    train_edges, train_edges_false, val_edges, val_edges_false, test_edges, test_edges_false = get_edges_split(data, val_prop = val_prop, test_prop = test_prop)\n",
    "    total_edges = np.concatenate((train_edges,train_edges_false,val_edges,val_edges_false,test_edges,test_edges_false))\n",
    "    data.train_pos,data.train_neg = len(train_edges),len(train_edges_false)\n",
    "    data.val_pos, data.val_neg = len(val_edges), len(val_edges_false)\n",
    "    data.test_pos, data.test_neg = len(test_edges), len(test_edges_false)\n",
    "    data.total_edges = total_edges\n",
    "    data.total_edges_y = torch.cat((torch.ones(len(train_edges)), torch.zeros(len(train_edges_false)), torch.ones(len(val_edges)), torch.zeros(len(val_edges_false)),torch.ones(len(test_edges)), torch.zeros(len(test_edges_false)))).long()\n",
    "\n",
    "    # delete val_pos and test_pos\n",
    "    edge_list = np.array(data.edge_index).T.tolist()\n",
    "    for edges in val_edges:\n",
    "        edges = edges.tolist()\n",
    "        if edges in edge_list:\n",
    "            # if not in edge_list, mean it is a self loop\n",
    "            edge_list.remove(edges)\n",
    "            edge_list.remove([edges[1], edges[0]])\n",
    "    for edges in test_edges:\n",
    "        edges = edges.tolist()\n",
    "        if edges in edge_list:\n",
    "            edge_list.remove(edges)\n",
    "            edge_list.remove([edges[1], edges[0]])\n",
    "    data.edge_index = torch.Tensor(edge_list).long().transpose(0, 1)\n",
    "\n",
    "    # edge index sampling\n",
    "    random_edge_num = 2500\n",
    "    indices = np.random.choice((data.edge_index).size(1), (random_edge_num,), replace=False)\n",
    "    indices = np.sort(indices)\n",
    "    sample_data_edge_index = data.edge_index[:, indices]\n",
    "\n",
    "    boundary_matrix0_, boundary_matrix1_ = compute_boundary_matrix(data, sample_data_edge_index)\n",
    "\n",
    "    L0u, L1f = compute_hodge_matrices(boundary_matrix0_, boundary_matrix1_)\n",
    "    L0u = torch.tensor(L0u, dtype=torch.float32)  # convert hodge matrix to tensor format\n",
    "    L1f = torch.tensor(L1f, dtype=torch.float32)\n",
    "    #print(L0u.size())\n",
    "    #print(L1f.size())\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data.total_edges_y.to(device)\n",
    "    model, data = SIMGAE(data, num_features, num_classes,\n",
    "                               hodge_laplacians=[L0u.to(device), L1f.to(device)]).to(device), data.to(device)\n",
    "    return model, data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Now, use SIMGAE to run the experiments of Link prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QtTc1_2vn6NR",
    "outputId": "f118401a-841e-471f-ea82-d645c63d36e8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2708, 2154)\n",
      "(2154, 131)\n",
      "epoch is: 20\n",
      "0.8006332316500167\n",
      "epoch is: 40\n",
      "0.8646648064884558\n",
      "epoch is: 60\n",
      "0.8761294799693504\n",
      "epoch is: 80\n",
      "0.9027888215819224\n",
      "epoch is: 100\n",
      "0.9224074368575518\n",
      "epoch is: 120\n",
      "0.9368503231216297\n",
      "epoch is: 140\n",
      "0.9429802368112883\n",
      "epoch is: 160\n",
      "0.9442091110179416\n",
      "epoch is: 180\n",
      "0.9442091110179416\n",
      "epoch is: 200\n",
      "0.946262053810233\n",
      "epoch is: 220\n",
      "0.9495872428400006\n",
      "epoch is: 240\n",
      "0.9496306148708237\n",
      "epoch is: 260\n",
      "0.9496306148708237\n",
      "epoch is: 280\n",
      "0.9500065058046234\n",
      "epoch is: 300\n",
      "0.951640185632292\n",
      "epoch is: 320\n",
      "0.9534762682704678\n",
      "epoch is: 340\n",
      "0.9534762682704678\n",
      "epoch is: 360\n",
      "0.9534762682704678\n",
      "epoch is: 380\n",
      "0.9534762682704678\n",
      "epoch is: 400\n",
      "0.9534762682704678\n",
      "epoch is: 420\n",
      "0.9534762682704678\n",
      "epoch is: 440\n",
      "0.9534762682704678\n",
      "epoch is: 460\n",
      "0.9534762682704678\n",
      "epoch is: 480\n",
      "0.9551533201289595\n",
      "epoch is: 500\n",
      "0.9571195188596047\n",
      "epoch is: 520\n",
      "0.9571195188596047\n",
      "epoch is: 540\n",
      "0.9571195188596047\n",
      "epoch is: 560\n",
      "0.9571195188596047\n",
      "epoch is: 580\n",
      "0.9571195188596047\n",
      "epoch is: 600\n",
      "0.9571195188596047\n",
      "epoch is: 620\n",
      "0.9571195188596047\n",
      "epoch is: 640\n",
      "0.9573074643265046\n",
      "epoch is: 660\n",
      "0.957567696511443\n",
      "epoch is: 680\n",
      "0.957567696511443\n",
      "epoch is: 700\n",
      "0.957567696511443\n",
      "epoch is: 720\n",
      "0.9588688574361346\n",
      "epoch is: 740\n",
      "0.9601989330480418\n",
      "epoch is: 760\n",
      "0.9618470702193178\n",
      "epoch is: 780\n",
      "0.9618470702193178\n",
      "epoch is: 800\n",
      "0.9618470702193178\n",
      "epoch is: 820\n",
      "0.9618470702193178\n",
      "epoch is: 840\n",
      "0.9618470702193178\n",
      "epoch is: 860\n",
      "0.9618470702193178\n",
      "epoch is: 880\n",
      "0.9618470702193178\n",
      "epoch is: 900\n",
      "0.9618470702193178\n",
      "epoch is: 920\n",
      "0.9618470702193178\n",
      "epoch is: 940\n",
      "0.9618470702193178\n",
      "epoch is: 960\n",
      "0.9620494730298255\n",
      "epoch is: 980\n",
      "0.9635530367650248\n",
      "epoch is: 1000\n",
      "0.9638566409807862\n",
      "epoch is: 1020\n",
      "0.9638566409807862\n",
      "epoch is: 1040\n",
      "0.9638566409807862\n",
      "epoch is: 1060\n",
      "0.9638566409807862\n",
      "epoch is: 1080\n",
      "0.9638566409807862\n",
      "epoch is: 1100\n",
      "0.9638566409807862\n",
      "epoch is: 1120\n",
      "0.9638566409807862\n",
      "epoch is: 1140\n",
      "0.9638566409807862\n",
      "epoch is: 1160\n",
      "0.9638566409807862\n",
      "epoch is: 1180\n",
      "0.9638566409807862\n",
      "epoch is: 1200\n",
      "0.9638566409807862\n",
      "epoch is: 1220\n",
      "0.9638566409807862\n",
      "epoch is: 1240\n",
      "0.9638566409807862\n",
      "epoch is: 1260\n",
      "0.9638566409807862\n",
      "epoch is: 1280\n",
      "0.9638566409807862\n",
      "Early stop! Min loss:  tensor(0.3030, grad_fn=<BinaryCrossEntropyBackward0>) , Max accuracy:  0.9608833884620697 , Max roc:  0.9638566409807862\n"
     ]
    }
   ],
   "source": [
    "dataset=Planetoid('./data/'+\"Cora\",\"Cora\",transform=T.NormalizeFeatures())\n",
    "# dataset = PygLinkPropPredDataset(name=\"ogbl-ddi\", root='./dataset/') #download the dataset\n",
    "\n",
    "wait_total= 300\n",
    "total_epochs = 4000\n",
    "\n",
    "\n",
    "#print(\"test\")\n",
    "data = dataset[0]\n",
    "model, data = call(data, dataset.name, data.x.size(1), dataset.num_classes)\n",
    "model.apply(weights_init)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=1e-4)\n",
    "best_val_acc = test_acc_same = test_acc_diff = test_acc = 0.0\n",
    "best_val_roc = test_roc_same = test_roc_diff = test_roc = 0.0\n",
    "best_val_loss = np.inf\n",
    "# train and val/test\n",
    "# train and val/test\n",
    "wait_step = 0\n",
    "for epoch in range(1, total_epochs + 1):\n",
    "    \n",
    "    pred = train()\n",
    "    val_loss, val_roc, val_acc, tmp_test_roc, tmp_test_acc = test()\n",
    "    if val_roc >= best_val_roc:\n",
    "        test_acc = tmp_test_acc\n",
    "        test_roc = tmp_test_roc\n",
    "        best_val_acc = val_acc\n",
    "        best_val_roc = val_roc\n",
    "        best_val_loss = val_loss\n",
    "        wait_step = 0\n",
    "    else:\n",
    "        wait_step += 1\n",
    "        if wait_step == wait_total:\n",
    "            print('Early stop! Min loss: ', best_val_loss, ', Max accuracy: ', best_val_acc,', Max roc: ', best_val_roc)\n",
    "            break\n",
    "    if epoch %20==0:\n",
    "        print(\"epoch is:\", epoch)\n",
    "        print(best_val_roc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eB1leasmwm09"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
